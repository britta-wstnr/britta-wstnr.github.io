<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Vision, Memory, and Language</title>
    <link>https://britta-wstnr.github.io/</link>
    <description>Recent content on Vision, Memory, and Language</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 01 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://britta-wstnr.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Subsampling channels for robust connectivity estimation</title>
      <link>https://britta-wstnr.github.io/posts/subsamplingbeamf/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://britta-wstnr.github.io/posts/subsamplingbeamf/</guid>
      <description>New series: Explaining papers [#1]
Lately, we published a new paper on estimating functional connectivity from electrophysiological data (Westner, Kujala, Gross, &amp;amp; Schoffelen, 2024). Let me give you a short description of what we did!
Estimating functional connectivity from electrophysiological (i.e., EEG or MEG) data means that one wants to see if any brain areas show activity that is somehow synchronised (although this synchronisation can be shifted in time: think of two people clapping together or clapping alternatingly - both is considered a synchronisation in the neuroscience world).</description>
    </item>
    
    <item>
      <title>Tips for teaching data analysis tutorials and workshops</title>
      <link>https://britta-wstnr.github.io/posts/tutorialworkshop/</link>
      <pubDate>Thu, 28 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://britta-wstnr.github.io/posts/tutorialworkshop/</guid>
      <description>Yesterday, I gave a workshop for Cutting Gardens tutors on how to teach MNE-Python. It was my first time teaching such a &amp;ldquo;meta workshop&amp;rdquo; - and below I am sharing some of the tips and thoughts I came up with during preparation. Part of it will be MNE-Python-specific, some of it should apply to any software workshop.
What should happen before the tutorial takes place? There is a few key points that should happen before the tutorial takes place:</description>
    </item>
    
    <item>
      <title>New: Resources page</title>
      <link>https://britta-wstnr.github.io/posts/newresources/</link>
      <pubDate>Wed, 15 Mar 2023 16:56:03 +0100</pubDate>
      
      <guid>https://britta-wstnr.github.io/posts/newresources/</guid>
      <description>There is a new content page on my website that links resources which I have created. At this point, it contains lectures and teaching material for MEG and EEG data analysis - but I will keep updating it whenever I create any new teaching material or tutorials.
If M/EEG data analysis is something you want to learn more about: go check it out here!</description>
    </item>
    
    <item>
      <title>I have seen this before. Pattern completion in the human visual system and its role for memory</title>
      <link>https://britta-wstnr.github.io/posts/mariecurie/</link>
      <pubDate>Wed, 26 Oct 2022 15:20:10 +0200</pubDate>
      
      <guid>https://britta-wstnr.github.io/posts/mariecurie/</guid>
      <description>From 2020 to 2022, I was funded by a Marie Curie Individual Fellowship of the EU Horizon 2020 scheme. This allowed me to join the lab of Prof. Floris de Lange at the Donders Institute at the Radboud University in Nijmegen to research visual anticipation and its relation to memory. Unfortunately, this fellowship was overshadowed by the COVID-19 pandemic, so progress on the project was a little slower than anticipated.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://britta-wstnr.github.io/posts/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://britta-wstnr.github.io/posts/about/</guid>
      <description>Picture credit: Marlene Meyer
Hi!
I am Britta Westner, an Assistant Professor at the Donders Institute and Radboudumc in The Netherlands. Here, I am working in the department of Medical Neuroscience.
My current research focuses mainly on the intersection of language and memory. I am closely working together with the lab of Assoc.-Prof. VitÃ³ria Piai. Since my background is in visual neuroscience, I am naturally also interested in the intersection of language and vision.</description>
    </item>
    
    
    <item>
      <title>Contact</title>
      <link>https://britta-wstnr.github.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://britta-wstnr.github.io/contact/</guid>
      <description>Physical address:
Trigon building Kapittelweg 29
6525 EN Nijmegen
If you want to write me an email, you can do so via:
firstname.lastname [at] donders.ru.nl</description>
    </item>
    
    <item>
      <title>News</title>
      <link>https://britta-wstnr.github.io/news/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://britta-wstnr.github.io/news/</guid>
      <description>Here, I report things like published papers, conferences I will or just have attended, workshops etc. as short news items.
2025 ðŸ“„ Irina has published her latest paper on the preplanning of linguistic representations, a project I got to be part of. Congratulations, Irina! Now out in Cognitive Neuropsychology (July).
ðŸ“„ Read about what is not great when it comes to the state of open source in (electrophys) neuroscience &amp;ndash; now in Imaging Neuroscience (May).</description>
    </item>
    
    <item>
      <title>Resources</title>
      <link>https://britta-wstnr.github.io/resources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://britta-wstnr.github.io/resources/</guid>
      <description>On this page, I am collecting some resources that I created, mostly for data analysis of MEG and EEG data.
Source reconstruction of M/EEG data If you would like to gain some experience with hands-on source reconstruction and best practices using MNE-Python, check out this material from the source reconstruction best practices workshop at CuttingEEGX in Nijmegen:
https://github.com/britta-wstnr/CuttingEEGX_Workshop
For the lab of VitÃ³ria Piai, I am creating a source reconstruction pipeline in FieldTrip.</description>
    </item>
    
    <item>
      <title>Selected Publications</title>
      <link>https://britta-wstnr.github.io/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://britta-wstnr.github.io/publications/</guid>
      <description>You can find my full publication list on Google Scholar. I also have an ORCID.
Peer-reviewed papers Chupina I, BU Westner, A Roelofs, and V Piai. 2025.
Speakers preplan lexical and phonological representations in semantically constraining linguistic contexts.
Cognitive Neuropsychology, https://doi.org/10.1080/02643294.2025.2515831.
Westner, BU*, DR McCloy*, E Larson*, A Gramfort, DS Katz, AM Smith, A Delorme, V Litvak, S Makeig, R Oostenveld, JM Schoffelen, and TM Tierney. 2025.
Cycling on the Freeway: The Perilous State of Open Source Neuroscience Software.</description>
    </item>
    
    <item>
      <title>Teaching</title>
      <link>https://britta-wstnr.github.io/teaching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://britta-wstnr.github.io/teaching/</guid>
      <description>I am teaching the recording and processing of electrophysiological signals across different programs at Radboud University. I am also the deputy specialization coordinator for the Medical Neuroscience specializations within the Master Biomedical Sciences. Below, you can see in which courses I am currently teaching!
Neuroimaging I
Cognitive Neuroscience Research Master
In this course, I am teaching several lectures as an introduction to EEG and MEG. We talk about acquisition, methods, and how this is used in neuroscience research.</description>
    </item>
    
  </channel>
</rss>
